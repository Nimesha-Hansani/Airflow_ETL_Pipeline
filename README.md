# Airflow_ETL_Pipeline

Overview
This project demonstrates an end-to-end data engineering pipeline designed to automate the ETL (Extract, Transform, Load) process using industry-leading tools: AWS, DBT, Snowflake, and Apache Airflow. The pipeline ensures efficient, scalable, and automated data transformations to enable advanced analytics and business intelligence.

Tech Stack
AWS S3: Secure and scalable storage for raw data.
Snowflake: A powerful data warehouse for storing and querying large datasets.
DBT: A transformation tool that enables data modeling and testing in Snowflake.
Apache Airflow: A workflow orchestration tool to manage the ETL process.
Slack: Integrated for real-time alerting and notifications.


